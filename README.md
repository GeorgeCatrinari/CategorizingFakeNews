# 📰 Categorizing Fake News (Case Study)

## 📌 Descriere
Acest proiect este un **studiu de caz în procesarea limbajului natural (NLP)** și **machine learning**, având ca scop **clasificarea articolelor de știri în funcție de veridicitate** (fake news vs. real news).  

Proiectul parcurge etapele esențiale:
- Explorarea și curățarea datelor text.
- Preprocesarea limbajului natural (tokenizare, lematizare, eliminare stopwords).
- Construirea și antrenarea mai multor modele de clasificare.
- Compararea performanței între metode tradiționale (Naive Bayes, Logistic Regression, Random Forest) și modele moderne bazate pe **transformers** (ex. BERT).
- Evaluarea modelelor prin metrici de acuratețe, precizie, recall și F1-score.

---

## 🛠️ Tehnologii utilizate
- **Python 3.11**
- **scikit-learn** – modele de machine learning clasice
- **spaCy** – procesare NLP avansată
- **TextBlob** și **VADER Sentiment** – analiză de sentiment
- **Gensim** – word embeddings și topic modeling
- **PyTorch** – rețele neuronale și deep learning
- **pandas, matplotlib, seaborn** – analiză și vizualizare de date
- **NLTK** – instrumente de NLP de bază

---

## 📊 Rezultate
- Analiză exploratorie detaliată a dataset-ului.
- Construirea unui pipeline NLP pentru curățarea și vectorizarea textului.
- Modele testate: **Naive Bayes, Logistic Regression, Random Forest, BERT**.
- Obținerea unor scoruri competitive de clasificare pe setul de test.
- Vizualizări comparative ale performanțelor.
